{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import data_clean #this file does the following preprocessing. I threw it all in a function so I could easily perform the same steps on the holdout_.csv data as the training data.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/brenthowe/datascience/data sets/svg/train_test_.csv')\n",
    "df_original = df\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print pd.DataFrame(df['Unnamed: 0'].unique()).describe() # This looks like a unique identifier\n",
    "# print pd.DataFrame(df['System ID'].unique()).describe() # 137042 unique values here...likely doesn't carry any useful information\n",
    "\n",
    "df.drop(['Unnamed: 0', 'System ID'], 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assume Created Date Time is correlated with purchasing opportunity day\n",
    "\n",
    "df['Created Date Time'] = pd.to_datetime(df['Created Date Time']) # convert to pandas datetime object\n",
    "df['day_of_week'] = df['Created Date Time'].dt.dayofweek # create day of week variable\n",
    "df['month'] = df['Created Date Time'].dt.month # create month variable\n",
    "\n",
    "# no major holidays in dataset time frame so won't create a holiday dummy\n",
    "\n",
    "df.drop(['Created Date Time'], 1, inplace=True)\n",
    "\n",
    "# print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print pd.DataFrame(df['Neustar Result Code'].unique()).describe() #6 unique values\n",
    "# print df['Neustar Result Code'].unique()\n",
    "\n",
    "df['Neustar Result Code'] = df['Neustar Result Code']\n",
    "# df.ix[df['Neustar Result Code'].isnull(), 'Neustar Result Code'] = -1\n",
    "df['Neustar Result Code'].fillna(value=999, inplace=True)\n",
    "\n",
    "# print df['Neustar Result Code'].unique()\n",
    "\n",
    "# print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print pd.DataFrame(df['Lead Source'].unique()).describe() #183 unique values\n",
    "\n",
    "le.fit(df['Lead Source'])\n",
    "df['Lead Source'] = le.transform(df['Lead Source']) \n",
    "\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print df['Smoker'].unique()\n",
    "\n",
    "df.ix[df['Smoker']=='FALSE', 'Smoker'] = 'No'\n",
    "df.ix[df['Smoker']=='OE State (Not Required)', 'Smoker'] = np.NaN\n",
    "df.ix[df['Smoker']=='N', 'Smoker'] = 'No'\n",
    "df.ix[df['Smoker']=='1', 'Smoker'] = 'Yes'\n",
    "df.ix[df['Smoker']=='TZT.Leads.Runtime.Domain.Models.Field', 'Smoker'] = np.NaN\n",
    "df.ix[df['Smoker']=='TRUE', 'Smoker'] = 'Yes'\n",
    "df.ix[df['Smoker']=='Y', 'Smoker'] = 'Yes'\n",
    "\n",
    "df['Smoker'].fillna(value='0', inplace=True)\n",
    "\n",
    "le.fit(df['Smoker'])\n",
    "df['Smoker'] = le.transform(df['Smoker']) \n",
    "\n",
    "# print df['Smoker'].describe()\n",
    "\n",
    "# print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print df['Emails'].unique()\n",
    "\n",
    "df['Emails'].fillna(value=df['Emails'].median(), inplace=True) #use median because the distribution is skewed\n",
    "\n",
    "le.fit(df['Emails'])\n",
    "df['Emails'] = le.transform(df['Emails']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Looks like birthdate may be age in days, so I'll leave it as it is.\n",
    "\n",
    "# Use median value in place of a missing value\n",
    "df['Birthdate'].fillna(value=df['Birthdate'].median(), inplace=True) #use median because the distribution is skewed\n",
    "\n",
    "# print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print df['Gender'].unique()\n",
    "\n",
    "df.ix[df['Gender']=='F', 'Gender'] = 'Female'\n",
    "df.ix[df['Gender']=='M', 'Gender'] = 'Male'\n",
    "\n",
    "df['Gender'].fillna(value='0', inplace=True)\n",
    "\n",
    "le.fit(df['Gender'])\n",
    "df['Gender'] = le.transform(df['Gender']) \n",
    "\n",
    "# print df['Gender'].describe()\n",
    "\n",
    "# print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print df['Applicant State/Province'].unique()\n",
    "\n",
    "df['Applicant State/Province'].fillna(value='0', inplace=True)\n",
    "\n",
    "le.fit(df['Applicant State/Province'])\n",
    "df['Applicant State/Province'] = le.transform(df['Applicant State/Province'])\n",
    "\n",
    "# print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['l'] = df['Applicant Zip/Postal Code'].astype(str).apply(lambda x: len(x))\n",
    "df.ix[(df['l']>5) & (df['l']<10), 'Applicant Zip/Postal Code'] = np.NaN\n",
    "\n",
    "df['Applicant Zip/Postal Code'] = df['Applicant Zip/Postal Code'].astype(str).apply(lambda x: x.split('-')[0] if len(x)>5 else x)\n",
    "df['Applicant Zip/Postal Code'] = df['Applicant Zip/Postal Code'].astype(str).apply(lambda x: '0' + x if len(x)==4 else x)\n",
    "\n",
    "# d = df[df['l']==3]\n",
    "# print d['Applicant Zip/Postal Code'].unique()\n",
    "\n",
    "df['Applicant Zip/Postal Code'] = df['Applicant Zip/Postal Code'].astype(str).apply(lambda x: '00' + x if (len(x)==3) & (x!='nan') else x)\n",
    "\n",
    "# df['Applicant Zip/Postal Code'] = df['Applicant Zip/Postal Code'].astype(float)\n",
    "# df.ix[df['Applicant Zip/Postal Code'].isnull(), 'Applicant Zip/Postal Code'] = -1\n",
    "\n",
    "df['zip'] = df['Applicant Zip/Postal Code']\n",
    "\n",
    "df.drop(['l', 'Applicant Zip/Postal Code'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zip_average_income():\n",
    "    df = pd.read_csv('/Users/brenthowe/datascience/galvanize/project/data/14zpallagi.csv')\n",
    "    df_sum = df.groupby('zipcode')[['N02650', 'A02650']].sum()\n",
    "    df_sum['mean_income'] = df_sum['A02650']/df_sum['N02650']\n",
    "    df_sum.drop(['N02650', 'A02650'], 1, inplace=True)\n",
    "    df_sum['zip'] = df_sum.index.astype('str')\n",
    "    df_sum['zip'] = df_sum.zip.apply(lambda x: x.zfill(5))\n",
    "    df_sum.set_index('zip', inplace=True)\n",
    "\n",
    "    us_income = float(df_sum.loc['00000'].values)\n",
    "    df_sum.drop(df_sum.index[0], inplace=True)\n",
    "    df_sum['zip'] = df_sum.index\n",
    "    return us_income, df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df2 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62029.4407391\n"
     ]
    }
   ],
   "source": [
    "# df = df2\n",
    "\n",
    "us_income, df_sum = zip_average_income()\n",
    "\n",
    "df_sum['mean_income'] = df_sum['mean_income']*1000\n",
    "df = df.merge(df_sum, how='left', on='zip')\n",
    "\n",
    "print df['mean_income'].mean()\n",
    "df['mean_income'].fillna(value=df['mean_income'].mean(), inplace=True) #approximate mean income in the United States\n",
    "\n",
    "# print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_median = pd.read_csv('income_by_zipcode.txt', sep='\\t', index_col=False)\n",
    "df_median['zip'] = df_median['zipcode, median_income'].str[:5]\n",
    "df_median['zip'] = df_median['zip'].apply(lambda x: '0'+ x if len(x)==4 else x)\n",
    "\n",
    "df_median['median_income'] = df_median['zipcode, median_income'].str[8:].apply(lambda x: x.replace(\",\",\"\"))\n",
    "df_median.drop('zipcode, median_income', 1, inplace=True)\n",
    "\n",
    "df = df.merge(df_median, how='left', on='zip')\n",
    "\n",
    "df.ix[(df.median_income == '') | (df.median_income == ' '), 'median_income'] = np.nan\n",
    "\n",
    "df.median_income = df.median_income.astype(float)\n",
    "\n",
    "df['median_income'].fillna(value='51939', inplace=True) #approximate median income in the United States\n",
    "df['median_income'] = df['median_income'].astype(float)\n",
    "\n",
    "df.drop(['zip', 'Applicant City'], 1, inplace=True)\n",
    "# print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['target'].fillna(value=0, inplace=True)\n",
    "\n",
    "# print df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df[['Neustar Result Code', 'Lead Source', 'Smoker', 'Emails', 'Birthdate', 'Gender', 'Applicant State/Province', 'day_of_week', 'month', 'mean_income', 'median_income']]\n",
    "\n",
    "y_train = df.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode the categorical variables\n",
    "enc = OneHotEncoder(categorical_features = [0, 1, 2, 5, 6, 7, 8])\n",
    "X_train = enc.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I put the above code in a file named data_clean.py (in a function called data_clean), so I would not have to copy and paste the above code below when I needed to preprocess the holdout_.csv data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train, y_train = data_clean.data_clean('/Users/brenthowe/datascience/data sets/svg/train_test_.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "param_dict = {'n_estimators': [10, 50, 100, 500],\n",
    "    'max_features': ['auto', 5, 10, 20, 25]}\n",
    "# param_dict = {'n_estimators': [10],\n",
    "#     'max_features': [5]}\n",
    "gsCV_rf = GridSearchCV(rf, param_dict, n_jobs = -1, scoring='roc_auc')\n",
    "gsCV_rf.fit(X_train, y_train)\n",
    "\n",
    "print gsCV_rf.best_params_\n",
    "print gsCV_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature importance plot\n",
    "rf = RandomForestClassifier(n_estimators=55, max_features=25)\n",
    "rf.fit(X_train, y_train)\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print indices[:15]\n",
    "\n",
    "# # Print the feature ranking\n",
    "# print(\"Feature ranking:\")\n",
    "\n",
    "# for f in range(X.shape[1]):\n",
    "#     print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# # Plot the feature importances of the forest\n",
    "# plt.figure()\n",
    "# plt.title(\"Feature importances\")\n",
    "# plt.bar(range(X.shape[1]), importances[indices],\n",
    "#        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "# plt.xticks(range(X.shape[1]), indices)\n",
    "# plt.xlim([-1, X.shape[1]])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the holdout_.csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = data_clean.data_clean('/Users/brenthowe/datascience/data sets/svg/holdout_.csv', train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = gsCV_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdout = pd.read_csv('/Users/brenthowe/datascience/data sets/svg/holdout_.csv')\n",
    "holdout['predictions'] = y_test_pred\n",
    "\n",
    "holdout.to_csv('/Users/brenthowe/datascience/data sets/svg/holdout_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# talk about how I can deal with missing values and the approach I take here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.ix[df.fico_range == ran, 'fair'] = 1\n",
    "\n",
    "# df_median['l'] = df_median['zip'].apply(lambda x: len(x))\n",
    "# print df_median['l'].describe()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
