{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from numpy import fft\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Assuming there is actually no effect of the marketing campaign on sales, we would expect to see this or more extreme data less than 5% of the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Assuming the null is correct, I would expect to get a p-value less than 0.05 5 times. The probability of the null actually being correct (conditional on the data of the first subsample) is 0.05 (probability of a type 1 error). \n",
    "\n",
    "The probability the null is correctly rejected based on the first test is 0.95 (1- the prob. of a type 1 error). Conditional on the null not being correct, the probability it is not rejected in subsequent tests is equal to the probability of a type 2 error (which I'll denote by beta_i, where i corresponds to the subsample). Since I don't know beta_i for all i (though it would be affected by factors such as sample size), it would be used to calculate the expected number of times the test stat is less than 0.05. After arriving at this value (call it T), the expected value of times the p-value is less than 0.05 is 0.05*(5) + 0.95*(T). \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a\n",
    "[2]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# b\n",
    "[num%7 for num in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# c\n",
    "np.random.normal(10, 3, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[sum(vec[x:x+7]) for x in range(0, len(vec), 7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../hackerrank_data/skill-assessment/DSTakeHome/prog1.csv')\n",
    "df[df['state']=='OH']['transactions'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling a data as signal plus noise, underfitting is not capturing enough of the signal, whereas overfitting is capturing too much noise. \n",
    "\n",
    "This should be avoided because it means the model does not generalize as well to other subsamples where the noise is likely different. \n",
    "\n",
    "If your model does not generalize well to other independent datasets (drawn from the same population). One way to get a sense of this is through cross-validation---i.e., is there a large difference in the value of your scoring metric between your training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using K-means, perform the K-means algorithm for various values of k. For each, calculate the sum of squared error (i.e., the distance of each point to its final centroid, squared, and summed over all datas points). Plot this for each value of k and try to find an elbow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There is possibly a yearly seasonal component in the data. Only testing on the last month may not reveal whether the extent of the seasonality was captured by the model. The second method may have difficulties fully assessing parameter stability across years since you're training on multiple years. A possible improvement (in terms of robustness) is a type of cross-validation in which you train separately on each possible two year pairing (year 1 and year2, year 1 and year 3, year 2 and year3) and test against the data from the left out year (year 3, year 2, and year 1, respectively), taking the average (or min, or some other statistic) across the three folds. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read data in\n",
    "df_ts1 = pd.read_csv('../hackerrank_data/skill-assessment/DSTakeHome/ts1.csv')\n",
    "df_ts2 = pd.read_csv('../hackerrank_data/skill-assessment/DSTakeHome/ts2.csv')\n",
    "df_ts3 = pd.read_csv('../hackerrank_data/skill-assessment/DSTakeHome/ts3.csv')\n",
    "\n",
    "df_ts1.date = pd.to_datetime(df_ts1.date)\n",
    "df_ts1.index = df_ts1.date\n",
    "df_ts1.drop(['date'], 1, inplace=True)\n",
    "\n",
    "df_ts2.date = pd.to_datetime(df_ts2.date)\n",
    "df_ts2.index = df_ts2.date\n",
    "df_ts2.drop(['date'], 1, inplace=True)\n",
    "\n",
    "df_ts3.date = pd.to_datetime(df_ts3.date)\n",
    "df_ts3.index = df_ts3.date\n",
    "df_ts3.drop(['date'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that plots the series\n",
    "def ts_plot(df):\n",
    "    fig = plt.figure(figsize=(18,8))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts_plot(df_ts1)\n",
    "ts_plot(df_ts2)\n",
    "ts_plot(df_ts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a function that plots the acf and pcf\n",
    "def acf_pcf_plot(df, lags):\n",
    "    fig = plt.figure(figsize=(18,8))\n",
    "    ax1 = fig.add_subplot(2,1,1)\n",
    "    fig = plot_acf(df, lags=lags, ax=ax1)\n",
    "    ax2 = fig.add_subplot(2,1,2)\n",
    "    fig = plot_pacf(df, lags=lags, ax=ax2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ts1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acf_pcf_plot(df_ts1, 28) #shows a strong seasonal component, s=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ts1_diff = df_ts1.diff(periods=7).dropna() #take a seasonal difference\n",
    "acf_pcf_plot(df_ts1_diff, 28) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would include the s=7 lag of the target variable as well as an SMA(1) term since there is a negative spike in the ACF at lag 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ts2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df_ts2[df_ts2.target==0] #looks like the target is 0 on the 4th of July, Thanksgiving, and Christmas\n",
    "\n",
    "acf_pcf_plot(df_ts2, 600) #shows a strong seasonal component, with at a lag of a year and half year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#what does it look like after dropping the zero holidays?\n",
    "df_ts2_noholi = df_ts2[df_ts2.target!=0]\n",
    "acf_pcf_plot(df_ts2_noholi, 600) #don't see much if any correlation\n",
    "# acf_pcf_plot(df_ts2_noholi, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I throwout the zeros (which are perfectly explained by the holidays listed above) and then would include just a constant since there doesn't appear to be any MA or AR signatures and it seems to be stationary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ts3.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ts3_diff = df_ts3.diff(periods=39).dropna() #seasonal differencing at frequency of 39 or 40 periods\n",
    "ts_plot(df_ts3_diff)\n",
    "acf_pcf_plot(df_ts3_diff, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot of the seasonally differenced series still does not look stationary. Nevertheless, I'd add a 40 period lag and an AR term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the data and convert it to a series with the date as the index\n",
    "df_ts4 = pd.read_csv('../hackerrank_data/skill-assessment/DSTakeHome/ts4.csv')\n",
    "df_ts5 = pd.read_csv('../hackerrank_data/skill-assessment/DSTakeHome/ts5.csv')\n",
    "\n",
    "df_ts4.date = pd.to_datetime(df_ts4.date)\n",
    "df_ts4.index = df_ts4.date\n",
    "df_ts4.drop(['date'], 1, inplace=True)\n",
    "\n",
    "df_ts5.date = pd.to_datetime(df_ts5.date)\n",
    "df_ts5.index = df_ts5.date\n",
    "df_ts5.drop(['date'], 1, inplace=True)\n",
    "\n",
    "df_ts4_test = pd.read_csv('../hackerrank_data/skill-assessment/DSTakeHome/ts4_test.csv')\n",
    "df_ts4_test.date = pd.to_datetime(df_ts4_test.date)\n",
    "df_ts4_test.index = df_ts4_test.date\n",
    "df_ts4_test.drop(['date'], 1, inplace=True)\n",
    "\n",
    "df_ts5_test = pd.read_csv('../hackerrank_data/skill-assessment/DSTakeHome/ts5_test.csv')\n",
    "df_ts5_test.date = pd.to_datetime(df_ts5_test.date)\n",
    "df_ts5_test.index = df_ts5_test.date\n",
    "df_ts5_test.drop(['date'], 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fourier transform function...x is the x is the data, n_predict is the number of predictions, and n_harm is the number of harmonics\n",
    "def fourierExtrapolation(x, n_predict, n_harm):\n",
    "    n = x.size\n",
    "    t = np.arange(0, n)\n",
    "    p = np.polyfit(t, x, 1)         # find linear trend in x\n",
    "    x_notrend = x - p[0] * t        # detrended x\n",
    "    x_freqdom = fft.fft(x_notrend)  # detrended x in frequency domain\n",
    "    f = fft.fftfreq(n)              # frequencies\n",
    "    indexes = range(n)\n",
    "    # sort indexes by frequency, lower -> higher\n",
    "    indexes.sort(key = lambda i: np.absolute(f[i]))\n",
    " \n",
    "    t = np.arange(0, n + n_predict)\n",
    "    restored_sig = np.zeros(t.size)\n",
    "    for i in indexes[:1 + n_harm * 2]:\n",
    "        ampli = np.absolute(x_freqdom[i]) / n   # amplitude\n",
    "        phase = np.angle(x_freqdom[i])          # phase\n",
    "        restored_sig += ampli * np.cos(2 * np.pi * f[i] * t + phase)\n",
    "    return restored_sig + p[0] * t\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ts4.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts_plot(df_ts4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the first differenced ts has lowest variance, suggesting first differencing is appropriate\n",
    "print df_ts4.std()\n",
    "\n",
    "df_ts4_diff = df_ts4.diff(periods=1).dropna()\n",
    "print df_ts4_diff.std()\n",
    "\n",
    "df_ts4_diff2 = df_ts4_diff.diff(periods=1).dropna()\n",
    "print df_ts4_diff2.std()\n",
    "\n",
    "acf_pcf_plot(df_ts4, 60) #also suggests first differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# checking whether the original and first-differenced data measure stationary? yes\n",
    "dftest = adfuller(df_ts4.target, autolag='AIC')\n",
    "print dftest\n",
    "\n",
    "dftest = adfuller(df_ts4_diff.target, autolag='AIC')\n",
    "print dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts_plot(df_ts4_diff) #visually looks stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acf_pcf_plot(df_ts4, 60)\n",
    "acf_pcf_plot(df_ts4_diff, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these diagnostics, I fit three models to the training data: ARIMA(1,0,0), ARIMA(0,1,1), and a Fourier decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ARIMA(1,0,0)\n",
    "model = ARIMA(df_ts4, (1,0,0)).fit(trend='c')\n",
    "model1_pred = model.forecast(30)[0]\n",
    "\n",
    "mae = np.mean(np.abs(df_ts4_test.target.values - model.forecast(30)[0])) #mean absolute error\n",
    "\n",
    "print \"ARIMA(1,0,0) MAE: {0}\".format(mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ARIMA(0,1,1)\n",
    "model = ARIMA(df_ts4, (0,1,1)).fit(trend='c')\n",
    "model2_pred = model.forecast(30)[0]\n",
    "\n",
    "mae = np.mean(np.abs(df_ts4_test.target.values - model.forecast(30)[0])) #mean absolute error\n",
    "\n",
    "print \"ARIMA(0,1,1) MAE: {0}\".format(mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fourier\n",
    "n_predict = 30\n",
    "extrapolation_ts4 = fourierExtrapolation(df_ts4.target.values, n_predict, 1)\n",
    "mae = np.mean(np.abs(df_ts4_test.target.values - extrapolation_ts4[-30:]))\n",
    "print \"Fourier MAE: {0}\".format(mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latter scores lowest of the three. Writing these predictions to file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('ts4_pred.csv', extrapolation_ts4, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the original series with the three predictions and the actual data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m1 = pd.DataFrame(model1_pred, columns=['target'])\n",
    "m1.index = pd.date_range(start='2011-08-18', periods=30)\n",
    "\n",
    "m2 = pd.DataFrame(model2_pred, columns=['target'])\n",
    "m2.index = pd.date_range(start='2011-08-18', periods=30)\n",
    "\n",
    "extrapolation_ts4_test = pd.DataFrame(extrapolation_ts4[-30:], columns=['target'])\n",
    "extrapolation_ts4_test.index = pd.date_range(start='2011-08-18', periods=30)\n",
    "\n",
    "fig = plt.figure(figsize=(18,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(df_ts4)\n",
    "ax.plot(df_ts4_test, 'b', label='Actual')\n",
    "ax.plot(m1, 'r', label='ARIMA(1,0,0)')\n",
    "ax.plot(m2, 'k', label='ARIMA(0,1,1)')\n",
    "ax.plot(extrapolation_ts4_test, 'g', label='Fourier Decomposition')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ts5.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts_plot(df_ts5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftest = adfuller(df_ts5.target, autolag='AIC')\n",
    "print dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acf_pcf_plot(df_ts5, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these preliminary diagnostics, the series looks a lot like white noise. I'll predict with the mean and a Fourier decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mean\n",
    "model1_pred = [float(df_ts5.mean())]*30\n",
    "\n",
    "mae = np.mean(np.abs(df_ts5_test.target.values - model1_pred)) #mean absolute error\n",
    "\n",
    "print \"MAE of the mean: {0}\".format(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fourier\n",
    "n_predict = 30\n",
    "extrapolation_ts5 = fourierExtrapolation(df_ts5.target.values, n_predict, 3)\n",
    "\n",
    "mae = np.mean(np.abs(df_ts5_test.target.values - extrapolation_ts5[-30:]))\n",
    "print \"Fourier MAE: {0}\".format(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latter scores lowest of the two. Writing these predictions to file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('ts5_pred.csv', extrapolation_ts5, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the original series with the two predictions and the actual data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m1 = pd.DataFrame(model1_pred, columns=['target'])\n",
    "m1.index = pd.date_range(start='2016-08-31', periods=30)\n",
    "\n",
    "extrapolation_ts5_test = pd.DataFrame(extrapolation_ts5[-30:], columns=['target'])\n",
    "extrapolation_ts5_test.index = pd.date_range(start='2016-08-31', periods=30)\n",
    "\n",
    "fig = plt.figure(figsize=(18,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(df_ts5)\n",
    "ax.plot(df_ts5_test, 'b', label='Actual')\n",
    "ax.plot(m1, 'r', label='Mean')\n",
    "ax.plot(extrapolation_ts5_test, 'g', label='Fourier Decomposition')\n",
    "ax.set_ylim([145, 155])\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
